{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells requires jupyter and notebook package.\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells requires jupyter and notebook package.\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType,  StringType, TimestampType, FloatType\n",
    "import pyspark.sql.functions as fn\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells requires jupyter and notebook package.\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# print('Please input path to folder location where movies.dat, users.dat, ratings.dat is available \\n')\n",
    "# folder_path = input()\n",
    "\n",
    "# print('Please input path to folder where you want to store the output \\n')\n",
    "# output_folder_path = input()\n",
    "\n",
    "# print('Please enter an integer to show top data\\n')\n",
    "# top_number = int(input())\n",
    "\n",
    "# For Command Line Arguments\n",
    "\n",
    "if len(sys.argv) != 4:\n",
    "    print(\"Usage: MovieLensProject <inputFilesFolderPath> <outputFolderPath> <intNumberForTopValues>\", file= sys.stderr)\n",
    "    sys.exit(-1)\n",
    "    \n",
    "    \n",
    "folder_path = sys.argv[1]\n",
    "output_folder_path = sys.argv[2]\n",
    "top_number = sys.argv[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells requires jupyter and notebook package.\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"MovieLens\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells requires jupyter and notebook package.\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# Movies data reading\n",
    "movie_cols = [ StructField(\"MovieID\", IntegerType(), True),\n",
    "               StructField(\"Title\", StringType(), True),\n",
    "               StructField(\"Genres\", StringType(), True)\n",
    "              ]\n",
    "movie_schema = StructType(movie_cols)\n",
    "\n",
    "df_movies = spark.read.csv(f'{folder_path}/movies.dat', sep = \"::\", header=False, schema = movie_schema)\n",
    "\n",
    "# Split the Genres by |\n",
    "df_movies = df_movies.withColumn(\"Genres\", fn.explode(fn.split(df_movies[\"Genres\"], \"\\\\|\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells requires jupyter and notebook package.\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# Users data reading\n",
    "\n",
    "empty_rdd = spark.sparkContext.emptyRDD()\n",
    "\n",
    "df_users = spark.createDataFrame(data = empty_rdd, schema = StructType([]))\n",
    "\n",
    "if os.path.exists(f'{folder_path}/users.dat'):\n",
    "    users_cols = [ StructField(\"UserID\", IntegerType(), True),\n",
    "                  StructField(\"Gender\", StringType(), True),\n",
    "                  StructField(\"Age\", IntegerType(), True),\n",
    "                  StructField(\"Occupation\", IntegerType(), True),\n",
    "                  StructField(\"Zip-code\", IntegerType(), True)\n",
    "\n",
    "    ]\n",
    "\n",
    "    users_schema = StructType(users_cols)\n",
    "\n",
    "    df_users = spark.read.csv(f'{folder_path}/users.dat', sep=\"::\", header=False, schema=users_schema)\n",
    "\n",
    "elif os.path.exists(f'{folder_path}/tags.dat'):\n",
    "    tags_cols = [StructField(\"UserID\", IntegerType(), True),\n",
    "                StructField(\"MovieID\", IntegerType(), True),\n",
    "                StructField(\"Tags\",StringType(),True),\n",
    "                StructField(\"Timestamp\", IntegerType(), True)\n",
    "    ]\n",
    "    tags_schema = StructType(tags_cols)\n",
    "    df_users = spark.read.csv(f'{folder_path}/tags.dat', sep=\"::\", header=False, schema=tags_schema)\n",
    "    df_users = df_users.withColumn(\"TimestampParsed\", fn.from_unixtime(fn.col(\"Timestamp\")) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells requires jupyter and notebook package.\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# Ratings data reading\n",
    "\n",
    "ratings_cols = [StructField(\"UserID\", IntegerType(), True),\n",
    "                StructField(\"MovieID\", IntegerType(), True),\n",
    "                StructField(\"Rating\",FloatType(),True),\n",
    "                StructField(\"Timestamp\", IntegerType(), True)\n",
    "\n",
    "]\n",
    "\n",
    "ratings_schema = StructType(ratings_cols)\n",
    "\n",
    "df_ratings = spark.read.csv(f'{folder_path}/ratings.dat', sep = \"::\", header=False, schema = ratings_schema)\n",
    "\n",
    "# Converting epoch seconds to timestamp\n",
    "\n",
    "df_ratings = df_ratings.withColumn(\"TimestampParsed\", fn.from_unixtime(fn.col(\"Timestamp\")) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating temp tables/views for the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells requires jupyter and notebook package.\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "df_movies.createOrReplaceTempView(\"Movies\")\n",
    "df_ratings.createOrReplaceTempView(\"Ratings\")\n",
    "\n",
    "if df_users.count() > 0:\n",
    "    df_users.createOrReplaceTempView(\"Users\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Top 5 Genres in each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = '''\n",
    "            SELECT CAST(ratingYear AS STRING) AS ratingYearStr, Genres, CAST(avgRating AS STRING) avgRatingstr \n",
    "            FROM (\n",
    "                    SELECT Genres, ratingYear, avgRating, DENSE_RANK() OVER (PARTITION BY ratingYear ORDER BY avgRating DESC) rnk\n",
    "                    FROM (\n",
    "                            SELECT Genres, ratingYear, ROUND(AVG(Rating), 2) avgRating\n",
    "                            FROM (\n",
    "                                    SELECT m.Title, m.Genres, r.Rating, EXTRACT(YEAR FROM r.TimestampParsed) as ratingYear\n",
    "                                    FROM Movies m\n",
    "                                    INNER JOIN Ratings r\n",
    "                                        ON r.MovieID = m.MovieID\n",
    "                                ) t\n",
    "                            GROUP BY Genres, ratingYear\n",
    "                        ) b\n",
    "                ) c\n",
    "            WHERE rnk <= 5\n",
    "            '''\n",
    "\n",
    "# Save the result of the query to a text file\n",
    "df_top_genres = spark.sql(sql_query)\n",
    "df_top_genres = df_top_genres.withColumn(\"op\", fn.concat_ws(\",\", fn.col(\"ratingYearStr\"), fn.col(\"Genres\"), fn.col(\"avgRatingstr\")))\n",
    "\n",
    "df_top_genres.select(\"op\").write.text(f'{output_folder_path}/top_genres_each_year')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What are the k most popular movies for each season (summer, fall, winter, spring)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = '''\n",
    "            SELECT season, Title, CAST(avgRating AS STRING) avgRatingstr\n",
    "            FROM (\n",
    "                    SELECT season, Title, avgRating, \n",
    "                           DENSE_RANK() OVER (PARTITION BY season ORDER BY avgRating DESC) rnk\n",
    "                    FROM (\n",
    "                            SELECT r.season, m.Title, AVG(Rating) avgRating\n",
    "                            FROM (\n",
    "                                    SELECT MovieId, Rating,\n",
    "                                        CASE\n",
    "                                            WHEN month(cast(TimestampParsed AS date)) IN (12, 1, 2) THEN 'Winter'\n",
    "                                            WHEN month(cast(TimestampParsed AS date)) IN (3, 4, 5) THEN 'Spring'\n",
    "                                            WHEN month(cast(TimestampParsed AS date)) IN (6, 7, 8) THEN 'Summer'\n",
    "                                            WHEN month(cast(TimestampParsed AS date)) IN (9, 10, 11) THEN 'Fall'\n",
    "                                            ELSE 'Invalid Month'\n",
    "                                        END AS season\n",
    "                                    FROM Ratings\n",
    "                                ) r\n",
    "                            INNER JOIN Movies m\n",
    "                                ON m.MovieId = r.MovieId\n",
    "                            GROUP BY r.season, m.Title\n",
    "                    ) b\n",
    "                ) c\n",
    "            WHERE rnk <= {}\n",
    "            '''.format(top_number)\n",
    "\n",
    "\n",
    "# Save the result of the query to a text file\n",
    "df_season_top = spark.sql(sql_query)\n",
    "df_season_top = df_season_top.withColumn(\"op\", fn.concat_ws(\",\", fn.col(\"season\"), fn.col(\"Title\"), fn.col('avgRatingstr')))\n",
    "\n",
    "df_season_top.select(\"op\").write.text(f'{output_folder_path}/top_season')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. What are the k most popular movies of all time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = '''SELECT DISTINCT m.Title, CAST(avgRating AS STRING) avgRatingstr\n",
    "               FROM Movies m\n",
    "               INNER JOIN (\n",
    "                           SELECT MovieID, ROUND(AVG(Rating),2) AS avgRating\n",
    "                           FROM Ratings\n",
    "                           GROUP BY MovieID\n",
    "                    ) r\n",
    "                       ON m.MovieID = r.MovieID\n",
    "              ORDER BY avgRatingstr DESC\n",
    "              LIMIT {}\n",
    "\n",
    "            '''.format(top_number)\n",
    "# Save the result of the query to a text file\n",
    "df_top_rated = spark.sql(sql_query)\n",
    "df_top_rated = df_top_rated.withColumn(\"op\", fn.concat_ws(\",\", fn.col(\"Title\"), fn.col('avgRatingstr')))\n",
    "df_top_rated.select(\"op\").write.text(f'{output_folder_path}/top_rated')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What are the k most popular movies for a particular year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = '''SELECT DISTINCT m.Title, CAST(r.avgRating AS STRING) avgRatingstr\n",
    "               FROM Movies m\n",
    "               INNER JOIN (\n",
    "                           SELECT MovieID, ROUND(AVG(Rating),2) AS avgRating\n",
    "                           FROM Ratings\n",
    "                           WHERE EXTRACT(YEAR FROM TimestampParsed) = {}\n",
    "                           GROUP BY MovieID\n",
    "                    ) r\n",
    "                       ON m.MovieID = r.MovieID\n",
    "              ORDER BY avgRatingstr DESC\n",
    "              LIMIT {}\n",
    "\n",
    "            '''.format(2000, top_number)\n",
    "\n",
    "df_top_rated_year = spark.sql(sql_query)\n",
    "df_top_rated_year = df_top_rated_year.withColumn(\"op\", fn.concat_ws(\",\", fn.col(\"Title\"), fn.col('avgRatingstr')))\n",
    "df_top_rated_year.select(\"op\").write.text(f'{output_folder_path}/top_rated_year_2000')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What are the k most popular movies based on gender?\n",
    " This part will only execute if the `users.dat` have __Gender__ column available i.e. for 1M dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Gender' in df_users.columns:\n",
    "    \n",
    "    sql_query = '''\n",
    "                    SELECT DISTINCT u.Gender, m.Title, ROUND(AVG(ra.Rating),2) AS avgRating, COUNT(ra.Rating) AS ratingCount\n",
    "                    FROM Movies m\n",
    "                    INNER JOIN Ratings ra ON m.MovieID = ra.MovieID\n",
    "                    INNER JOIN Users u ON ra.UserID = u.UserID\n",
    "                    WHERE u.Gender = 'F'\n",
    "                    GROUP BY m.Title, u.Gender\n",
    "                    HAVING ratingCount >= 250 --filtering out movies with less ratings to avoid skewness in result\n",
    "                    ORDER BY avgRating DESC\n",
    "                    LIMIT {}\n",
    "                '''.format(top_number)\n",
    "\n",
    "    \n",
    "    \n",
    "    df_top_rated_gender = spark.sql(sql_query)\n",
    "    df_top_rated_gender = df_top_rated_gender.withColumn(\"avgRatingstr\", fn.col(\"avgRating\").cast(\"string\"))\n",
    "    df_top_rated_gender = df_top_rated_gender.withColumn(\"op\", fn.concat_ws(\",\", fn.col(\"Gender\"), fn.col(\"Title\"), fn.col('avgRatingstr')))\n",
    "    df_top_rated_gender.select(\"op\").write.text(f'{output_folder_path}/top_rated_gender')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. What are the top k movies with the most ratings (presumably most popular) that have the lowest ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = ''' SELECT DISTINCT  m.Title, CAST(averageRatings AS STRING) averageRatings, CAST(totalRatings AS STRING) totalRatings\n",
    "                FROM Movies m\n",
    "                INNER JOIN(\n",
    "                            SELECT MovieID, COUNT(Rating) AS totalRatings, ROUND(AVG(Rating),2) AS averageRatings\n",
    "                            FROM Ratings\n",
    "                            GROUP BY MovieID\n",
    "\n",
    "                )r\n",
    "                    ON m.MovieID = r.MovieID\n",
    "                ORDER BY averageRatings ASC, totalRatings DESC\n",
    "                LIMIT {}\n",
    "\n",
    "            '''.format(top_number)\n",
    "df_high_count_low_rated = spark.sql(sql_query)\n",
    "df_high_count_low_rated = df_high_count_low_rated.withColumn(\"averageRatingsstr\", fn.col(\"averageRatings\").cast(\"string\"))\n",
    "df_high_count_low_rated = df_high_count_low_rated.withColumn(\"totalRatingsstr\", fn.col(\"totalRatings\").cast(\"string\"))\n",
    "df_high_count_low_rated = df_high_count_low_rated.withColumn(\"op\", fn.concat_ws(\",\", fn.col(\"Title\"), fn.col('averageRatingsstr'), fn.col('totalRatingsstr')))\n",
    "df_high_count_low_rated.select(\"op\").write.text(f'{output_folder_path}/high_count_low_rated')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6 (default, Aug 11 2023, 19:44:49) \n[Clang 15.0.0 (clang-1500.0.40.1)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
